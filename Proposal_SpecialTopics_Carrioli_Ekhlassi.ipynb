{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Special Topics Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Kian Ekhlassi\n",
    "- Olimpia Carrioli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic and outline\n",
    "\n",
    "### Main topic\n",
    "This lecture is concerned with the ethics of artificial intelligence development and employment. We will discuss the definition of ethics, the ethical implications of AI employment in warfare, considerations on privacy and surveillance, different definitions of fairness and their shortcomings, and, lastly, ethical implications of further AI advancement including robot rights and genetic engineering. \n",
    "\n",
    "\n",
    "### Learning goals for students \n",
    "\n",
    "- Students will grasp an understanding of why AI can be potentially dangerous when applied to warfare, specifically with autonomous weapons. \n",
    "- Students should know the differences between de-identification, K-anonymity, aggregate querying, differential privacy, and federated learning and why these strategies are crucial for maintaining privacy. \n",
    "- Students will learn what “fairness” means based on the most common definitions (individual fairness, group fairness, fairness through unawareness, equal outcome, equal opportunity, and equal impact) and what the fallacies of each definition are. \n",
    "- Students will learn what the alignment problem is. \n",
    "- The ultimate goal of this lecture is for students to reflect on the complexity of the ethical development of AI and the role of the next generation of technicians in mitigating the risks of such powerful technologies.\n",
    "\n",
    "\n",
    "\n",
    "### Outline of the topic\n",
    "\n",
    "  - #### Definition of Ethics\n",
    "    - __[‘Philosophical study of moral phenomena’](https://en.wikipedia.org/wiki/Ethics)__, any given system of moral values, meaning the result of reasoning about wrong and right.\n",
    "    - Examples of ways in which ethical  behavior varies across people and situations. Importance of having a diverse team for AI development.\n",
    "\n",
    "\n",
    "  - Autonomous weapons - third revolution in warfare\n",
    "    - __Ai is a dual use technology: neutral/life-improving tools (eg mapping) can be applied to warfare and to effectively create mass destruction weapons__ \n",
    "    - Cons: offload control, scale of attack is proportional to monetary capability to buy components, prone to selective attacks of minority groups, often untraceable, hackable. \n",
    "    - Pros: cheap, fast, maneuverable, do not get fatigued, not emotional, potentially less likely to cause unwanted casualties. \n",
    "    - Real life example - Iran’s attack on Israel, April 13th, all remotely controlled + Iron Dome uses AI. \n",
    "    - <ins>Class discussion</ins>: Is it ethical to offload the decision to take human lives to silicon? How do you feel about power being taken away from humans with autonomous systems? Do the pros outweigh the cons?   \n",
    "\n",
    "  - #### Privacy and surveillance\n",
    "    - __As we rely more on technology, more data is being collected without proper regulations (eg. [85 million surveillance cameras](https://www.comparitech.com/blog/vpn-privacy/us-surveillance-camera-statistics/) in USA, but privacy protection for medical and student records only)__\n",
    "    - Example: tik tok allows China to collect data in the USA (see [Tik Tok ban](https://www.nytimes.com/article/tiktok-ban.html))\n",
    "    - <ins>Class discussion</ins>: who should have data ownership? Improved services at the cost of privacy: where does the line lay?\n",
    "    - Overview of privacy enhancing strategies:\n",
    "      - De identification (eliminate personal info such as SSN). Problem: correlated variables can still lead to identification\n",
    "      - K-anonymity (every entry is indistinguishable from at least k-1 other entries)\n",
    "      - Aggregate querying (API returns information only if privacy conditions are met)\n",
    "      - Differential privacy (add noise to each query)\n",
    "      - Federated learning (centralized model trained locally on personal data)  \n",
    "\n",
    "  - #### Fairness and Bias\n",
    "    - __Any AI is just as fair as the data it is trained on. It is the engineer’s duty to ensure fairness in each step of the pipeline.__\n",
    "    - Overview of most common definitions of fairness:\n",
    "      - Individual fairness: treat individuals similarly regardless of their class\n",
    "      - Group fairness: treat groups similarly regardless of differences\n",
    "      - Fairness through unawareness: remove sensitive attributes (eg. race). Highly problematic because of autocorrelation, connected to de identification. \n",
    "      - Equal outcome: demographic parity (each class has the same outcome). Problematic due to baseline differences. <ins>Class discussion</ins>: examples of failing demographic parity?\n",
    "      - Equal opportunity: outcome based on true attributes; may result in unequal outcome. \n",
    "      - Equal impact: individuals with similar likelihood of X should be given equal opportunity. \n",
    "    - <ins>Class discussion</ins>: what are some practical ways in which we, as technicians, can move towards fairness and unbiased technologies? How does fairness, bias, and privacy relate to the Open Source movement? Can we optimize our model for all three?\n",
    "\n",
    "  - #### Future of work\n",
    "    - __As Ai progresses, we must face ethical questions ranging from disparity exacerbation, to biological improvement (is it ethical to pay for a more intelligent child?) to robot rights and the alignment problem.__\n",
    "    - [Alignment problem](https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6): build AI that is aligned with what humans want. Problem: getting humans aligned with themselves\n",
    "    - Evidence of relevance of these topics: [call to alt AI advancement](https://www.theguardian.com/technology/2023/mar/31/ai-research-pause-elon-musk-chatgpt) for 6 months (Elon Musk vs. Yann LeCun and Andrew Ng stance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedagogy\n",
    "\n",
    "\n",
    "### Readings\n",
    "\n",
    "1. _Artificial Intelligence: a Modern Approach_  Chapter 27.3 \n",
    "\n",
    "    There are 4 topics that are expected to be understood by students. These topics are <em>privacy and surveillance, fairness and bias, trust and transparency</em>, and <em>future of work</em>. This chapter dives into the details of why ethics within AI is important. To elaborate this point the authors explain the 4 topics elucidated above, and they express the pros and cons of AI in relation to those topics. Students are expected to read this chapter in order to glean insights on why AI is something that requires ethical guidelines.  \n",
    "\n",
    "2. [AI—The good, the bad, and the scary](https://eng.vt.edu/magazine/stories/fall-2023/ai.html)\n",
    "\n",
    "    This article from Virginia Tech contains the perspective of engineers within the field of AI. Each individual claims the potential “good”, the “bad” and the “scary” sides of AI. This article relates to some of the key points made in chapter 27 of Artificial Intelligence a Modern Approach. \n",
    "\n",
    "3. [Yuval Noah Harari: AI is a “social weapon of mass destruction” to humanit](https://www.youtube.com/watch?v=QsyY1CKzSww)\n",
    "\n",
    "    The main points made in this discussion with Yuval Noah Harari is that AI is the first technology invented that can create original ideas, and make decisions on its own. He continues to express why this can be extremely dangerous for humanity. His main claim is that AI takes power away from humans due to AI’s autonomy. Harari also theorizes that at some point stories (political, philosophical, economical, etc)  will be dominated by AI. The worries with technology in general is how fast their evolution is, Harari compares human evolution to technological evolution. Students should watch this video before lecture to get a broad sense of why AI can be considered dangerous.\n",
    "\n",
    "4. [Artificial Intelligence 2023 Legislation](https://www.ncsl.org/technology-and-communication/artificial-intelligence-2023-legislation)\n",
    "\n",
    "    This website contains the current status of AI bills per state in the United States. In total 18 different states enacted or adopted AI related bills. These bills cover a broad spectrum of AI related topics. Students should know the different categories pertaining to the different AI bills. Some important categories to note are elections, Education/training, government use, health use, effect on labor/employment, oversight/governance, and responsible use. Students should also review some of the bills that have been enacted, there are links on the website that grant access to the specific bill number/type. This website should help students realize how important ethical guidelines are, and how many States are actively regulating AI. \n",
    "\n",
    "\n",
    "### Lecture description\n",
    "\n",
    "-> Introduction of speakers (Both)  \n",
    "-> Definition of ethics (Olimpia)  \n",
    "-> Autonomous weapons - new wave in warfare (Olimpia)  \n",
    "-> Privacy and Surveillance (Both)  \n",
    "-> Fairness and Bias (Kian)  \n",
    "-> Future of Work (Kian)  \n",
    " \n",
    "\n",
    "### Active learning\n",
    "- __Discussion Question:__ How do you feel about power being taken away from humans with autonomous systems? Do the pros outweigh the cons? \n",
    "    - The discussion will take place in the first quarter of the lecture to get students thinking about this topic.The video listed in the pre-course material will broadly be summarized (assuming students already watched the video before lecture). We will ask students to talk amongst their peers about the question we pose. After 3-5 minutes of discussion we will regroup and ask students to share what they talked about. The total time for this exercise is 7 minutes.\n",
    "    - _Element covered:_ Autonomous weapons, offload of decisions to AI\n",
    "\n",
    "- __Discussion Question:__ Who should have data ownership? Improved services at the cost of privacy: where does the line lay?\n",
    "\n",
    "    - This question will be asked during the presentation of the privacy and surveillance portion of the lecture, after mention of the tik tok ban currently being discussed in the USA. We will ask the question to the whole class and pick 3 to 4 people to answer it. The question aims at fostering thoughts and discussion on data ownership and one’s personal stance on loss of privacy for enhanced technological performance.The total time allotted for this discussion is of 5 minutes maximum.\n",
    "    - _Elements covered:_ privacy, data ownership, surveillance\n",
    "\n",
    "- __Discussion Question:__ what are some practical ways in which we, as technicians, can move towards fairness and unbiased technologies? How does fairness, bias, and privacy relate to the Open Source movement? Can we optimize our model for all three?\n",
    "\n",
    "    - This question will be asked at the end of our presentation on fairness and bias. It is meant to encourage the class to reflect on our collective responsibility as technicians to strive for fair technology, and the difficulty of balancing fairness, bias, and privacy. We will ask the question to the class and select 3 to 4 students to share their answers. We expect this discussion to take no longer than 5 minutes.\n",
    "    - _Elements covered:_ bias, fairness, privacy, ‘open source’ movement\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates\n",
    "- 5/20/2024\n",
    "- 5/29/2024\n",
    "- 5/13/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Divide work evenly*\n",
    "* *Decide collaboratively which topics to cover, how to cover them, and who should be in charge of which part of the presentation*\n",
    "* *Meet once a week to update each other, communicate frequently through text*\n",
    "* *Be honest and patient with each other*\n",
    "* *Respect each other's time: let the partner know in advance if a meeting can not be attended*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to meet twice a week to check in on our progress and work together (Wednesdays 4:00pm, Saturdays 11:00am). We also agreed to work individually on our portion of the slides, and integrate them during our weekly meetings. Both Kian and Olimpia will complete the activities listed in the timeline below.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before/At Meeting|\n",
    "|---|---|---|\n",
    "| 5/8 |  4pm |  Finalize slides | \n",
    "| 5/11  |  11am |  Rehearse presentation individually | \n",
    "| 5/15  | 4pm  | Rehearse presentation together|\n",
    "| 5/18  | 11am  | Incorporate instructors feedback, finalize slides, submit final project  |\n",
    "| 5/19 | 11am | Gather necessary equipment for presentation|\n",
    "| 5/20 | 3pm | Final project presentation!|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
